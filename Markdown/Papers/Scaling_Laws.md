# Scaling laws for neural language models

## notes

-   paper deals with pretraining, not finetuning
